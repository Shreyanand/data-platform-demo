{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3347d3ec-10a7-4321-a5e6-9b1665e5dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install boto3 pyarrow python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05438fd-8b78-477b-90ca-ddbbfeee4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "_wsdedup = re.compile(r\"\\s+\")\n",
    "_usdedup = re.compile(r\"__+\")\n",
    "_rmpunc = re.compile(r\"[,.()&$/+-]+\")\n",
    "# 63 seems to be a common max column name length\n",
    "def snakify(name, maxlen=63):\n",
    "    if isinstance(name, list):\n",
    "        return [snakify(e) for e in name]\n",
    "    w = name.casefold().rstrip().lstrip()\n",
    "    w = w.replace(\"-\", \"_\")\n",
    "    w = _rmpunc.sub(\"\", w)\n",
    "    w = _wsdedup.sub(\"_\", w)\n",
    "    w = _usdedup.sub(\"_\", w)\n",
    "    w = w.replace(\"average\", \"avg\")\n",
    "    w = w.replace(\"maximum\", \"max\")\n",
    "    w = w.replace(\"minimum\", \"min\")\n",
    "    w = w.replace(\"absolute\", \"abs\")\n",
    "    w = w.replace(\"source\", \"src\")\n",
    "    w = w.replace(\"distribution\", \"dist\")\n",
    "    # these are common in the sample names but unsure of standard abbv\n",
    "    #w = w.replace(\"inference\", \"inf\")\n",
    "    #w = w.replace(\"emissions\", \"emis\")\n",
    "    #w = w.replace(\"intensity\", \"int\")\n",
    "    #w = w.replace(\"reported\", \"rep\")\n",
    "    #w = w.replace(\"revenue\", \"rev\")\n",
    "    w = w[:maxlen] \n",
    "    return w\n",
    "\n",
    "def snakify_columns(df, inplace=False, maxlen=63):\n",
    "    icols = df.columns.to_list()\n",
    "    ocols = snakify(icols, maxlen=maxlen)\n",
    "    scols = set(ocols)\n",
    "    if (len(set(ocols)) < len(ocols)):\n",
    "        raise ValueError(\"remapped column names were not unique!\")\n",
    "    rename_map = dict(list(zip(icols,snakify(icols))))\n",
    "    return df.rename(columns=rename_map, inplace=inplace)\n",
    "\n",
    "_p2smap = {\n",
    "    'string': 'varchar',\n",
    "    'Float64': 'double',\n",
    "    'Int64': 'bigint'\n",
    "}\n",
    "\n",
    "def pandas_type_to_sql(pt):\n",
    "    st = _p2smap.get(pt)\n",
    "    if st is not None:\n",
    "        return st\n",
    "    raise ValueError(\"unexpected pandas column type '{pt}'\".format(pt=pt))\n",
    "\n",
    "# add ability to specify optional dict for specific fields?\n",
    "# if column name is present, use specified value?\n",
    "def generate_table_schema_pairs(df):\n",
    "    ptypes = [str(e) for e in df.dtypes.to_list()]\n",
    "    stypes = [pandas_type_to_sql(e) for e in ptypes]\n",
    "    pz = list(zip(df.columns.to_list(), stypes))\n",
    "    return \",\\n\".join([\"    {n} {t}\".format(n=e[0],t=e[1]) for e in pz])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66daa759-b4a8-46f1-ae97-3e4788d9cb2d",
   "metadata": {},
   "source": [
    "## Example `credentials.env` file\n",
    "\n",
    "```\n",
    "# s3 credentials\n",
    "S3_ENDPOINT=https://s3.us-east-1.amazonaws.com\n",
    "S3_BUCKET=ocp-odh-os-demo-s3\n",
    "S3_ACCESS_KEY=xxx\n",
    "S3_SECRET_KEY=xxx\n",
    "\n",
    "# trino credentials\n",
    "TRINO_USER=xxx\n",
    "TRINO_PASSWD=xxx\n",
    "TRINO_HOST=trino-secure-odh-trino.apps.odh-cl1.apps.os-climate.org\n",
    "TRINO_PORT=443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b1acdc-0d1b-454a-ab6b-e76d8892acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values, load_dotenv\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "dotenv_dir = os.environ.get('CREDENTIAL_DOTENV_DIR', os.environ.get('PWD', '/opt/app-root/src'))\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / 'credentials.env'\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path,override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98a535e-08fc-47fb-bd83-23258088d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# Create an S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ['S3_ENDPOINT'],\n",
    "    aws_access_key_id=os.environ['S3_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_SECRET_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab43cbc7-ddcc-40c0-8ff5-aaffcb347709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "obj = s3.get_object(\n",
    "    Bucket=os.environ['S3_BUCKET'],\n",
    "    Key='urgentem/UrgentemDataSampleEmissionsTargetsDec2020.csv')\n",
    "\n",
    "# load the raw file from the bucket\n",
    "dfEmissions = (pd.read_csv(obj['Body'])).convert_dtypes()\n",
    "\n",
    "# convert columns to specific data types\n",
    "dfEmissions = dfEmissions.convert_dtypes()\n",
    "\n",
    "# map column names to a form that works for SQL\n",
    "snakify_columns(dfEmissions, inplace=True)\n",
    "#dfEmissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbbb8cc-889d-47a0-b4e7-ae2a83285168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 15 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   company_name                        19 non-null     string \n",
      " 1   isin                                19 non-null     string \n",
      " 2   target_type                         19 non-null     string \n",
      " 3   scope                               19 non-null     string \n",
      " 4   coverage_s1                         16 non-null     Float64\n",
      " 5   coverage_s2                         15 non-null     Float64\n",
      " 6   coverage_s3                         4 non-null      Int64  \n",
      " 7   reduction_ambition                  19 non-null     Float64\n",
      " 8   base_year                           19 non-null     Int64  \n",
      " 9   end_year                            19 non-null     Int64  \n",
      " 10  start_year                          19 non-null     Int64  \n",
      " 11  base_year_ghg_emissions_s1_tco2e    1 non-null      string \n",
      " 12  base_year_ghg_emissions_s1s2_tco2e  14 non-null     string \n",
      " 13  base_year_ghg_emissions_s3_tco2e    18 non-null     string \n",
      " 14  achieved_reduction                  19 non-null     Float64\n",
      "dtypes: Float64(4), Int64(4), string(7)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "# a way to examine the structure of a pandas data frame\n",
    "dfEmissions.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d823afe4-587d-4ee8-b481-e2edb0ae749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet has multiple options for appending or updating data\n",
    "# including adding new files, or appending, sharding directory trees, etc\n",
    "dfEmissions.to_parquet('/tmp/emissions.parquet', index=False)\n",
    "s3.upload_file(\n",
    "    Bucket=os.environ['S3_BUCKET'],\n",
    "    Key='urgentem/trino/itr_emissions_sample_test/emissions.parquet',\n",
    "    Filename='/tmp/emissions.parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82d3fb7-0040-4a6b-b3e4-62675f51a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trino\n",
    "conn = trino.dbapi.connect(\n",
    "    auth=trino.auth.BasicAuthentication(os.environ['TRINO_USER'], os.environ['TRINO_PASSWD']),\n",
    "    host=os.environ['TRINO_HOST'],\n",
    "    port=int(os.environ['TRINO_PORT']),\n",
    "    http_scheme='https',\n",
    "    verify=True,\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720b20bb-3350-478b-b362-38b9d46150d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this demonstration example, we just recreate table from scratch each time.\n",
    "# in live data platform there will need to be policies and mechanisms for either\n",
    "# appending new data, or overwriting old data, or saving off conditioned by a versioning number\n",
    "# this is a data governance topic\n",
    "cur.execute('drop table if exists hive.urgentem.itr_emissions_sample_test')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd26a9df-806e-488d-9920-39881fd7ce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create table if not exists default.urgentem.itr_emissions_sample_test(\n",
      "    company_name varchar,\n",
      "    isin varchar,\n",
      "    target_type varchar,\n",
      "    scope varchar,\n",
      "    coverage_s1 double,\n",
      "    coverage_s2 double,\n",
      "    coverage_s3 bigint,\n",
      "    reduction_ambition double,\n",
      "    base_year bigint,\n",
      "    end_year bigint,\n",
      "    start_year bigint,\n",
      "    base_year_ghg_emissions_s1_tco2e varchar,\n",
      "    base_year_ghg_emissions_s1s2_tco2e varchar,\n",
      "    base_year_ghg_emissions_s3_tco2e varchar,\n",
      "    achieved_reduction double\n",
      ") with (\n",
      "    format = 'parquet',\n",
      "    external_location = 's3a://ocp-odh-os-demo-s3/urgentem/trino/itr_emissions_sample_test/'\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sql schema that will correspond to the data types\n",
    "# of columns in the pandas DF\n",
    "# to-do: add some mechanisms for overriding types, either here\n",
    "# or on the pandas data-frame itself before we write it out\n",
    "schema = generate_table_schema_pairs(dfEmissions)\n",
    "\n",
    "tabledef = \"\"\"create table if not exists default.urgentem.itr_emissions_sample_test(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://ocp-odh-os-demo-s3/urgentem/trino/itr_emissions_sample_test/'\n",
    ")\"\"\".format(schema=schema)\n",
    "print(tabledef)\n",
    "\n",
    "# tables created externally may not show up immediately in cloud-beaver\n",
    "cur.execute(tabledef)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7c859b-15af-4ddc-a0fc-a26e029d0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test creation of new table\n",
    "#cur.execute('show tables in default.urgentem')\n",
    "#cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d62dec-c965-439d-90f2-0ea7fd7f87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that we can get data\n",
    "#cur.execute('select isin from default.urgentem.itr_emissions_sample_test')\n",
    "#cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd69ae-d334-4e51-934a-4375f31e5a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
